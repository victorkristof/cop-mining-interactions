{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbaseconda12cc5b1983ce432e8ce1d0fc698bd97b",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil.parser import parse\n",
    "import csv\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the all the new url inside html_link \n",
    "def extract_p_tags_45(html_link):\n",
    "    page_link = urllib.request.urlopen(html_link).read()\n",
    "    soup_link = BeautifulSoup(page_link)\n",
    "    paragraphes = soup_link.findAll('a',href = re.compile('\\d+'))\n",
    "    list_tp = []\n",
    "\n",
    "    for pa in paragraphes:\n",
    "        # doesn't use the link of the main page (all issues)\n",
    "        if(pa['href'] != '1200000e.html'):\n",
    "            html_link = 'https://enb.iisd.org/vol12/'+pa['href']\n",
    "            list_tp += extract_p_tags_rest(html_link)\n",
    "\n",
    "    return list_tp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_p_tags_66(html_link):\n",
    "    page = urllib.request.urlopen(html_link).read()\n",
    "\n",
    "    page_string = re.sub('<!-- WWW Designer Jeff Anderson janderson@iisd.ca --!>','',str(page))\n",
    "    #expression reguli√®re pour enelevr dans les tags \n",
    "    page_string = re.sub('<!-- www design jeff anderson janderson@iisd.ca ---!>','',str(page_string).lower())\n",
    " \n",
    "    soup = BeautifulSoup(page_string,'html.parser')\n",
    "    list_tp = soup.find_all('p')\n",
    "    #s =b'<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\\n'\n",
    "    return list_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the <p> tag from a specific html link\n",
    "def extract_p_tags_rest(html_link):\n",
    "    page = urllib.request.urlopen(html_link).read()\n",
    "    soup = BeautifulSoup(page,'html.parser')\n",
    "    list_tp = soup.find_all('p')\n",
    "    return list_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_csv_p_tags(csv_file):\n",
    "    f = open(csv_file)\n",
    "    csv_f = csv.reader(f)\n",
    "    k=0\n",
    "    list_pt = []\n",
    "    for row in csv_f:\n",
    "        \"\"\"\n",
    "        #Extract for 0 < Issue# < 45 \n",
    "        if(k>0 and int(row[4]) < 45 ):\n",
    "\n",
    "            list_pt += extract_p_tags_45(row[6])\n",
    "\n",
    "        \n",
    "        if(k>0 and  45 < int(row[4]) and  int(row[4]) <=66 ):\n",
    "\n",
    "            #check if URL still valid\n",
    "            print(row[6])\n",
    "            request = requests.get(row[6])\n",
    "            if(request.status_code == 200):\n",
    "                l = extract_p_tags_66(row[6])\n",
    "                list_pt += l\n",
    "\n",
    "        \"\"\"\n",
    "        #Extract for 66 < Issue# < 775\n",
    "        if(k>0 and 66 < int(row[4]) and int(row[4]) <80):\n",
    "\n",
    "            request = requests.get(row[6])\n",
    "            if(request.status_code == 200):\n",
    "                list_pt += extract_p_tags_rest(row[6])\n",
    "        \n",
    "\n",
    "        k +=1\n",
    "\n",
    "    return list_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tp(sentence):\n",
    "    s = re.sub(\"\\r\\n\\s\\s+\",\" \",sentence)\n",
    "    s = re.sub(\"\\r\\n\",\"\",s)\n",
    "    s = re.sub(\"\\s\\s+\",\" \",s)\n",
    "    s = re.sub(\"\\r\\n\",\"\",s)\n",
    "    \n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_meetings = extract_from_csv_p_tags('list_meetings.csv')\n",
    "list_p_tags = [clean_tp(str(line)) for line in list_meetings ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate list_p_tags.txt file\n",
    "outF = open(\"list_p_tags.txt\", \"w\")\n",
    "for line in list_p_tags:\n",
    "    # write line to output file\n",
    "    outF.write(str(line))\n",
    "    outF.write(\"\\n\")\n",
    "outF.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = re.sub(\"\\s\\s+\",\" \",s)\n",
    "    s = re.sub(\"\\r\\n\",\"\",s)"
   ]
  }
 ]
}
{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbaseconda12cc5b1983ce432e8ce1d0fc698bd97b",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil.parser import parse\n",
    "import csv\n",
    "import pandas as pd\n",
    "import requests\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import MWETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_txt_sentences(txt_file):\n",
    "    list_tp = open(txt_file)\n",
    "    return list_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a set of all the countries\n",
    "def extract_tokens_countries(type_word):\n",
    "\n",
    "    url = 'https://www.britannica.com/topic/list-of-countries-1993160'\n",
    "    page = urllib.request.urlopen(url).read()\n",
    "    soup = BeautifulSoup(page)\n",
    "    \n",
    "    countries = []\n",
    "    for link in soup.findAll('a',href=re.compile(\"https://www.britannica.com/place/\")):\n",
    "        c = re.sub(\"https://www.britannica.com/place/\", '',link.get('href'))\n",
    "\n",
    "        if(type_word == 'normal'):\n",
    "            list_c = (str(c)).split('-')\n",
    "        if(type_word == 'upper'):\n",
    "            list_c = (str(c).upper()).split('-')\n",
    "        if(type_word == 'lower'):\n",
    "            list_c = (str(c).lower()).split('-')\n",
    "\n",
    "        countries.append(list_c)\n",
    "    \n",
    "    return countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_list_countries(type_word):\n",
    "\n",
    "    url = 'https://www.britannica.com/topic/list-of-countries-1993160'\n",
    "    page = urllib.request.urlopen(url).read()\n",
    "    soup = BeautifulSoup(page)\n",
    "    \n",
    "    countries = []\n",
    "    for link in soup.findAll('a',href=re.compile(\"https://www.britannica.com/place/\")):\n",
    "        c = re.sub(\"https://www.britannica.com/place/\", '',link.get('href'))\n",
    "        \n",
    "        if(type_word == 'normal'):\n",
    "            list_c = (str(c)).split('-')\n",
    "            x = \" \"        \n",
    "            country = x.join(list_c)\n",
    "        if(type_word == 'upper'):\n",
    "            list_c = (str(c).upper()).split('-')\n",
    "            x = \" \"        \n",
    "            country = x.join(list_c)\n",
    "        if(type_word == 'lower'):\n",
    "            list_c = (str(c).lower()).split('-')\n",
    "            x = \" \"        \n",
    "            country = x.join(list_c)\n",
    "\n",
    "        countries.append(country)\n",
    "\n",
    "    print(countries)\n",
    "    return countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[['Afghanistan'],\n ['Albania'],\n ['Algeria'],\n ['Andorra'],\n ['Angola'],\n ['Antigua', 'and', 'Barbuda'],\n ['Argentina'],\n ['Armenia'],\n ['Australia'],\n ['Austria'],\n ['Azerbaijan'],\n ['The', 'Bahamas'],\n ['Bahrain'],\n ['Bangladesh'],\n ['Barbados'],\n ['Belarus'],\n ['Belgium'],\n ['Belize'],\n ['Benin'],\n ['Bhutan'],\n ['Bolivia'],\n ['Bosnia', 'and', 'Herzegovina'],\n ['Botswana'],\n ['Brazil'],\n ['Brunei'],\n ['Bulgaria'],\n ['Burkina', 'Faso'],\n ['Burundi'],\n ['Cabo', 'Verde'],\n ['Cambodia'],\n ['Cameroon'],\n ['Canada'],\n ['Central', 'African', 'Republic'],\n ['Chad'],\n ['Chile'],\n ['China'],\n ['Colombia'],\n ['Comoros'],\n ['Democratic', 'Republic', 'of', 'the', 'Congo'],\n ['Republic', 'of', 'the', 'Congo'],\n ['Costa', 'Rica'],\n ['Cote', 'dIvoire'],\n ['Croatia'],\n ['Cuba'],\n ['Cyprus'],\n ['Czech', 'Republic'],\n ['Denmark'],\n ['Djibouti'],\n ['Dominica'],\n ['Dominican', 'Republic'],\n ['East', 'Timor'],\n ['Ecuador'],\n ['Egypt'],\n ['El', 'Salvador'],\n ['Equatorial', 'Guinea'],\n ['Eritrea'],\n ['Estonia'],\n ['Eswatini'],\n ['Ethiopia'],\n ['Fiji', 'republic', 'Pacific', 'Ocean'],\n ['Finland'],\n ['France'],\n ['Gabon'],\n ['The', 'Gambia'],\n ['Georgia'],\n ['Germany'],\n ['Ghana'],\n ['Greece'],\n ['Grenada'],\n ['Guatemala'],\n ['Guinea'],\n ['Guinea', 'Bissau'],\n ['Guyana'],\n ['Haiti'],\n ['Honduras'],\n ['Hungary'],\n ['Iceland'],\n ['India'],\n ['Indonesia'],\n ['Iran'],\n ['Iraq'],\n ['Ireland'],\n ['Israel'],\n ['Italy'],\n ['Jamaica'],\n ['Japan'],\n ['Jordan'],\n ['Kazakhstan'],\n ['Kenya'],\n ['Kiribati'],\n ['North', 'Korea'],\n ['South', 'Korea'],\n ['Kosovo'],\n ['Kuwait'],\n ['Kyrgyzstan'],\n ['Laos'],\n ['Latvia'],\n ['Lebanon'],\n ['Lesotho'],\n ['Liberia'],\n ['Libya'],\n ['Liechtenstein'],\n ['Lithuania'],\n ['Luxembourg'],\n ['Madagascar'],\n ['Malawi'],\n ['Malaysia'],\n ['Maldives'],\n ['Mali'],\n ['Malta'],\n ['Marshall', 'Islands'],\n ['Mauritania'],\n ['Mauritius'],\n ['Mexico'],\n ['Micronesia', 'republic', 'Pacific', 'Ocean'],\n ['Moldova'],\n ['Monaco'],\n ['Mongolia'],\n ['Montenegro'],\n ['Morocco'],\n ['Mozambique'],\n ['Myanmar'],\n ['Namibia'],\n ['Nauru'],\n ['Nepal'],\n ['Netherlands'],\n ['New', 'Zealand'],\n ['Nicaragua'],\n ['Niger'],\n ['Nigeria'],\n ['North', 'Macedonia'],\n ['Norway'],\n ['Oman'],\n ['Pakistan'],\n ['Palau'],\n ['Panama'],\n ['Papua', 'New', 'Guinea'],\n ['Paraguay'],\n ['Peru'],\n ['Philippines'],\n ['Poland'],\n ['Portugal'],\n ['Qatar'],\n ['Romania'],\n ['Russia'],\n ['Rwanda'],\n ['Saint', 'Kitts', 'and', 'Nevis'],\n ['Saint', 'Lucia'],\n ['Saint', 'Vincent', 'and', 'the', 'Grenadines'],\n ['Samoa', 'island', 'nation', 'Pacific', 'Ocean'],\n ['San', 'Marino', 'republic', 'Europe'],\n ['Sao', 'Tome', 'and', 'Principe'],\n ['Saudi', 'Arabia'],\n ['Senegal'],\n ['Serbia'],\n ['Seychelles'],\n ['Sierra', 'Leone'],\n ['Singapore'],\n ['Slovakia'],\n ['Slovenia'],\n ['Solomon', 'Islands'],\n ['Somalia'],\n ['South', 'Africa'],\n ['Spain'],\n ['Sri', 'Lanka'],\n ['Sudan'],\n ['South', 'Sudan'],\n ['Suriname'],\n ['Sweden'],\n ['Switzerland'],\n ['Syria'],\n ['Taiwan'],\n ['Tajikistan'],\n ['Tanzania'],\n ['Thailand'],\n ['Togo'],\n ['Tonga'],\n ['Trinidad', 'and', 'Tobago'],\n ['Tunisia'],\n ['Turkey'],\n ['Turkmenistan'],\n ['Tuvalu'],\n ['Uganda'],\n ['Ukraine'],\n ['United', 'Arab', 'Emirates'],\n ['United', 'Kingdom'],\n ['United', 'States'],\n ['Uruguay'],\n ['Uzbekistan'],\n ['Vanuatu'],\n ['Vatican', 'City'],\n ['Venezuela'],\n ['Vietnam'],\n ['Yemen'],\n ['Zambia'],\n ['Zimbabwe']]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_tokens_countries('normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all the sentence with at least one party inside\n",
    "def extract_sentences_with_one_country(list_tp_cleaned):\n",
    "    #create tokenizer and the set who will contains all the sentences\n",
    "    tokens_countries = extract_tokens_countries('normal')+ extract_tokens_countries('upper')+ extract_tokens_countries('lower')\n",
    "    lists_countries = extract_list_countries('normal')+ extract_list_countries('upper')+ extract_list_countries('lower')\n",
    "    tokenizer = MWETokenizer(tokens_countries, separator=' ')\n",
    "    sentences_country = set()\n",
    "\n",
    "    for line in list_tp_cleaned:\n",
    "        #split sentence with tokenizer to detect a country\n",
    "        line = line.replace(\",\",\"\")\n",
    "        line_splited = word_tokenize(line)\n",
    "        tokens = tokenizer.tokenize(line_splited)\n",
    "        for country in lists_countries: \n",
    "            if(country in tokens):\n",
    "                sentences_country.add(line)\n",
    "                break\n",
    "\n",
    "    return sentences_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sentences_cleaned  = extract_from_txt_sentences('sentences_cleaned.txt')\n",
    "list_with_one_entity = extract_sentences_with_one_country(list_sentences_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate list_sentence_with_country.txt file\n",
    "outF = open(\"list_sentence_with_one_country.txt\", \"w\")\n",
    "for line in list_with_one_entity :\n",
    "    # write line to output file\n",
    "    outF.write(line)\n",
    "outF.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ]
}
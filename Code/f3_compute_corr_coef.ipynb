{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# g4_compute_corr_coef\n",
    "Compute the coefficient of correlation between the original and generated dataset for the interventions. Plot also the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "importing Jupyter notebook from e2_extract_occ_original.ipynb\nimporting Jupyter notebook from g1_generate_dictionary.ipynb\nimporting Jupyter notebook from g3_generate_occurence_all.ipynb\nimporting Jupyter notebook from a2_extract_list_meetings.ipynb\nimporting Jupyter notebook from a1_compute_list_meeting.ipynb\nimporting Jupyter notebook from c1_extract_paragraphe_issue.ipynb\nIssue  34\nimporting Jupyter notebook from c2_extract_sentence_issue.ipynb\nimporting Jupyter notebook from e1_extract_occ_gen.ipynb\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.stats.stats import pearsonr  \n",
    "import scipy.stats as ss\n",
    "import import_ipynb\n",
    "import e2_extract_occ_original as e2\n",
    "import g1_generate_dictionary as g1 \n",
    "import g3_generate_occurence_all as g3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_issues_to_extract():\n",
    "    \"\"\"Find all issue in the original dataset. \"\"\"\n",
    "    lines = e2.extract_statement_count()\n",
    "    set_issue = set()\n",
    "    for l in lines[1:]:\n",
    "        set_issue.add(int(l[2]))\n",
    "    return list(set_issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gen_number(number, generated):\n",
    "    \"\"\"Create the vector with all intervention of each entity in the generated dataset for one issue. \"\"\"\n",
    "    g = []\n",
    "    for i in range(len(generated)):\n",
    "        if(generated[i][0] == number):\n",
    "            g.append(generated[i])\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_orig_number(number, original):\n",
    "    \"\"\"Create the vector with all intervention of each entity in the original dataset for one issue. \"\"\"\n",
    "    o = []\n",
    "    for i in range(len(original)):\n",
    "        if(original[i][0] == number):\n",
    "            o.append(original[i])\n",
    "    return o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def compute_corr_coef(number, generated, original):\n",
    "    \"\"\"find the correlation for one issue between the generated and original dataset. \"\"\"\n",
    "    gen_num = extract_gen_number(number, generated)\n",
    "    orig_num = extract_orig_number(number, original)\n",
    "    x = np.zeros((1,len(gen_num)))[0]\n",
    "    y = np.zeros((1,len(gen_num)))[0]\n",
    "    for i in range(len(gen_num)):\n",
    "        x[i] += float(gen_num[i][2])\n",
    "        y[i] += float(orig_num[i][2])\n",
    "  \n",
    "    x =  np.array(x).astype(np.float)\n",
    "    y = np.array(y).astype(np.float)\n",
    "\n",
    "    # If both have only zeros\n",
    "    if(sum(x) == 0 and sum(y)==0):\n",
    "        return 1\n",
    "\n",
    "    else:\n",
    "        return np.corrcoef(x,y, rowvar=True)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_corr():\n",
    "    \"\"\"For all the issues into the list of the original dataset find the coefficient of correaltion between both datasets\"\"\"\n",
    "    generated_occ, original_occ = g3.extract_all_intervention()\n",
    "\n",
    "    corr_coef = []\n",
    "    list_issues = find_issues_to_extract()\n",
    "    x_axis = []\n",
    "    y_axis = []\n",
    "    k=0\n",
    "\n",
    "    for i in range(45,594):\n",
    "        if(i in list_issues):\n",
    "            cc = compute_corr_coef(i, generated_occ, original_occ)\n",
    "            if(not math.isnan(float(cc))):\n",
    "                x_axis.append(i)\n",
    "                y_axis.append(cc)\n",
    "                corr_coef.append(cc)\n",
    "                if(cc < 0.6):\n",
    "                    k +=1\n",
    "                    print(i,cc)\n",
    " \n",
    "    print(\"Mean: \",np.mean(corr_coef))  \n",
    "    print(\"STD :\", np.std(corr_coef))       \n",
    "    return x_axis, y_axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr_coeff(x,y):\n",
    "    \"\"\"Plot all the coefficient of correlations\"\"\"\n",
    "    figsize = (16,9)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    csfont = {'fontname':'Helvetica','fontsize':'18' }\n",
    "    hfont = {'fontname':'Helvetica','fontsize':'16'}\n",
    "    #plt.title('Coefficient of correlation between the two dataset for each document',**csfont)\n",
    "    plt.xlabel('Documents ordered by reference', **hfont)\n",
    "    plt.ylabel('Coefficient of correlation', **hfont)\n",
    "    plt.scatter(x,y, color = 'dodgerblue')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bit15afa4b5d9a84aa2af9f4a46f3f973aa",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

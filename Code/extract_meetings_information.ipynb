{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the specific page to be able to extract information from it \n",
    "\n",
    "page = urllib.request.urlopen('https://enb.iisd.org/enb/vol12/').read()\n",
    "soup = BeautifulSoup(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Variable\n",
    "month = {'January':1,'February':2,'March':3,'April':4,'May':5,'June':6,'July':7,'August':8,'September':9,'October':10,'November':11,'December':12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that extracts a date from a given string by returning a tuple of int (day,month,year)\n",
    "def extract_date(sdate):\n",
    "    if(extract_number(sdate) == None ):\n",
    "        return sdate\n",
    "    \n",
    "    m = re.findall('\\d{4}|\\d{2}|January|February|March|April|May|June|July|August|September|October|November|December|\\d{1}',sdate)\n",
    "\n",
    "    if(len(m)==0):\n",
    "        d=0\n",
    "    if(len(m)==5):\n",
    "        d = (int(m[0]),month[m[1]],int(m[len(m)-1]))\n",
    "    if(len(m)==4):\n",
    "        d = (int(m[0]),month[m[2]],int(m[len(m)-1]))\n",
    "    if(len(m)==3):\n",
    "        if(m[0] in month.keys()):\n",
    "            d=(m[1],month[m[0]],m[2])\n",
    "        else :\n",
    "            d = (m[0],month[m[1]],m[2])\n",
    "    if(len(str(d[1])) == 1):\n",
    "        s = '0'+ str(d[1])\n",
    "    if(len(str(d[0])) == 1):\n",
    "        s = '0'+ str(d[2])\n",
    "    \n",
    "    d_str = str(d[2])+\"-\"+str(d[1])+\"-\"+str(d[0])\n",
    "    \n",
    "    return d_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that extracts digit from a given string and return an int \n",
    "\n",
    "def extract_number(sname):\n",
    "    \n",
    "    for i in sname.split():\n",
    "\n",
    "        if i.isdigit():\n",
    "            return int(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that helps to compose and order the list. Returns an ordered, by date, list who contains all the COPs with their attributes\n",
    "\n",
    "def compute_list(list_string):\n",
    "    list_cop = []\n",
    "\n",
    "    for s in list_string:\n",
    "        l = s.split('|')\n",
    "        list_cop.append((extract_number(l[0]),extract_date(l[1]),l[2]))\n",
    "        \n",
    "    list_cop.sort(key=lambda a: a[0], reverse=False)\n",
    "\n",
    "    return list_cop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------ COP ------------------------------ \n",
    "# Function that extract the list of all the COPs from a webpage and return a list containing all the COPs with their number, date and place\n",
    "\n",
    "def extract_list_cops(soup):\n",
    "    \n",
    "    # find all the different COPs (not named the same way)\n",
    "    \n",
    "    #Case 1 :\"COP\"+\"\\s\"+\"\\d\"+\"\\s\"+\".\"+\"\\s\"  // COP 1-9\n",
    "    list = soup.find_all(string=re.compile(\"COP\"+\"\\s\"+\"\\d\"+\"\\s\"+\".\"+\"\\s\"))\n",
    "\n",
    "    #Case 2 : \"COP\"+\"\\s\"+\"[1-2][0-9]\"+\"\\s\"+\".\"+\"\\s\"+\"\\d\" // COP 10,23,24,25\n",
    "    list += soup.find_all(string=re.compile(\"COP\"+\"\\s\"+\"[1-2][0-9]\"+\"\\s\"+\".\"+\"\\s\"+\"\\d\"))\n",
    "    \n",
    "    #Case 3 :\"COP\"+\"\\s\"+\"[1-2][0-9]\"+\"\\s\"+\".\"+\"\\s\"+\"CMP\"+\"\\s\"+\"\\d\"+\".\"+\".\" // COP 11,12,13,14,15,16,21,22\n",
    "    list_2 = soup.find_all(string=re.compile(\"COP\"+\"\\s\"+\"[1-2][0-9]\"+\"\\s\"+\".\"+\"\\s\"+\"CMP\"+\"\\s\"+\"\\d+\"+\"\\s\"))\n",
    "\n",
    "    # Case 4 : \"COP\"+\"\\s\"+\"[1-2][0-9]\"+\"\\s\"+\".\"+\"\\s\"+\"CMP\"+\"\\d\"+\"\\s\" //COP 17,18,19\n",
    "    list_3 = soup.find_all(string=re.compile(\"COP\"+\"\\s\"+\"[1-2][0-9]\"+\"\\s\"+\".\"+\"\\s\"+\"CMP\"+\"\\d+\"+\"\\s\"))\n",
    "    \n",
    "    # Clean the lists to have all the same structure\n",
    "    # Clean list_2\n",
    "    for i in range(len(list_2)) :\n",
    "        list_2[i] =  re.sub(\"- CMP\"+\"\\s\"+\".\"+\".\", '', list_2[i])\n",
    "\n",
    "    # Clean list_3\n",
    "    for i in range(len(list_3)) :\n",
    "        list_3[i] =  re.sub(\"- CMP\"+\".\", '', list_3[i])\n",
    "    \n",
    "    #combine all the lists\n",
    "    list += list_2\n",
    "    list += list_3\n",
    "   \n",
    "    return compute_list(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------ INC ------------------------------ \n",
    "# Function that extract the list of all the INCs from a webpage and return a list containing all the COPs with their number, date and place\n",
    "\n",
    "def extract_list_incs(soup):\n",
    "    \n",
    "    # find all the different INCs (not named the same way)\n",
    "    # Only one\n",
    "    \n",
    "    #Case 1 :\"INC\"+\"\\s\"+\"\\d+\"+\"\\s\"  // INC 11\n",
    "    list = soup.find_all(string=re.compile(\"INC\"+\"\\s\"+\"\\d+\"+\"\\s\"))\n",
    "\n",
    "    return compute_list(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------ SB ------------------------------ \n",
    "# Function that extract the list of all the SBs from a webpage and return a list containing all the COPs with their number, date and place\n",
    "\n",
    "def extract_list_sbs(soup):\n",
    "    \n",
    "    # find all the different INCs (not named the same way)\n",
    "\n",
    "    #Case 1 :\"SB\"+\"\\s\"+\"\\d+\"+\"\\s\"+\".\"+\"\\s\"+\"\\d+\"\n",
    "    list_1 = soup.find_all(string=re.compile(\"SB\"+\"\\s\"+\"\\d+\"+\"\\s\"+\".\"+\"\\s\"+\"\\d+\"))\n",
    "    \n",
    "    #Case 2 : \"SB\"+\"\\s\"+\"\\d+\"+\"\\s\"+\"-\"+\"\\s\"+\"AG\"+\".\"+\".\"+\"\\s\"+\"\\d\"+\"...\\d+\"\n",
    "    list_2 = soup.find_all(string=re.compile(\"SB\"+\"\\s\"+\"\\d+\"+\"\\s\"+\"-\"+\"\\s\"+\"AG\"+\".\"+\".\"+\"\\s\"+\"\\d\"+\"...\\d+\"))\n",
    "    \n",
    "    #Case 3 : \n",
    "    list_3 = soup.find_all(string=re.compile(\"SB\"+\"\\s\"+\"\\d+\"+\"\\s\"+\"-\"+\"\\s\"+\"AG\"+\"..\"+\"\\s\"+\"\\d\"+\"............\\d\"))\n",
    "    \n",
    "    #Case 4 : \n",
    "    list_4 = soup.find_all(string=re.compile(\"SB\"+\"-...\"))\n",
    "    \n",
    "    #Case 5 : \n",
    "    list_5 = soup.find_all(string=re.compile(\"SB\"+\"\\s\"+\"\\d+\"+\"\\s\"+\"- AWG...\"))\n",
    "    \n",
    "    # Clean list_2\n",
    "    for i in range(len(list_2)) :\n",
    "        list_2[i] =  re.sub(\"- AG\\d+ \\d \", '', list_2[i])\n",
    "    \n",
    "    for i in range(len(list_3)) :\n",
    "        list_3[i] =  re.sub(\"- AGBM \\d . AG....\", '', list_3[i])\n",
    "    \n",
    "    for i in range(len(list_4)) :\n",
    "        list_4[i] =  re.sub(\"-\", ' ', list_4[i])\n",
    "    \n",
    "    for i in range(len(list_5)) :\n",
    "        list_5[i] =  re.sub(\" . AWGs\", '', list_5[i])\n",
    "\n",
    "    list = list_1+list_2+list_3+list_4+list_5\n",
    "\n",
    "    return compute_list(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------ IPCC ------------------------------ \n",
    "# Function that extract the list of all the IPCCs from a webpage and return a list containing all the COPs with their number, date and place\n",
    "\n",
    "def extract_list_ipccs(soup):\n",
    "    \n",
    "    # find all the different IPCCs (not named the same way)\n",
    "    \n",
    "    #Case 1 :\"IPCC-\\d+ . \"\n",
    "    list = soup.find_all(string=re.compile(\"IPCC-\\d+ . \"))\n",
    "\n",
    "    for i in range(len(list)) :\n",
    "        list[i] =  re.sub(\"-\", ' ', list[i])\n",
    "        \n",
    "    return compute_list(list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------ AGBM ------------------------------ \n",
    "# Function that extract the list of all the AGMBs from a webpage and return a list containing all the COPs with their number, date and place\n",
    "\n",
    "def extract_list_agbms(soup):\n",
    "    \n",
    "    # find all the different AGBMs (not named the same way)    \n",
    "    #Case 1 : \"AGBM \\d+ . \\d+\"\n",
    "    list = soup.find_all(string=re.compile(\"AGBM \\d+ . \\d+\"))\n",
    "        \n",
    "    return compute_list(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------ UNFCCC WS ------------------------------ \n",
    "# Function that extract the list of all the UNFCC WS' from a webpage and return a list containing all the COPs with their number, date and place\n",
    "def extract_list_unfcccs(soup):\n",
    "    \n",
    "    # find all the different UNFCCC WSs (not named the same way)    \n",
    "    list = soup.find_all(string=re.compile(\"UNFCCC WS.............\"))\n",
    "    separated = []\n",
    "    for l in list:\n",
    "        sep = l.split(\"|\")\n",
    "        sep[0] = re.sub(\"UNFCCC WS\", '', sep[0])  \n",
    "        sep[1] = extract_date(sep[1])\n",
    "        separated.append(sep)\n",
    "    return separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------ ADP ------------------------------ \n",
    "# Function that extract the list of all the ADPs from a webpage and return a list containing all the COPs with their number, date and place\n",
    "def extract_list_adps(soup):\n",
    "    \n",
    "    # find all the different AGBMs (not named the same way)    \n",
    "    #Case 1 : \"AGBM \\d+ . \\d+\"\n",
    "    list = soup.find_all(string=re.compile(\"ADP \\d......\"))\n",
    "    separated = []\n",
    "    for l in list:\n",
    "        sep = l.split(\"|\")\n",
    "        sep[0] = re.sub(\"ADP\", '', sep[0])  \n",
    "        sep[1] = extract_date(sep[1])\n",
    "        separated.append(sep)\n",
    "    return separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
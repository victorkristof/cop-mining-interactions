{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bit162d60da764a43dc83edcb73a443ab01",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# e1_compute_occurence_entities\n",
    "From the file list_meetings.csv, find the number of invertions of each entitx for each issues. Return a file named occurences.csv with the collected informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil.parser import parse\n",
    "import csv\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import MWETokenizer\n",
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_list_meetings():\n",
    "    \"\"\" Open the csv file that contain all the meetings. \"\"\"\n",
    "    f = open('list_meetings.csv')\n",
    "    return csv.reader(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_occurrence_issue(occurences_meetings, s):\n",
    "        with open(s, \"w\", newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "        #header\n",
    "                writer.writerow(('entity','interventions'))\n",
    "                writer.writerows(occurences_meetings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tuple(line):\n",
    "    \"\"\" Extract tuple for each row from Paula's dataset. \"\"\"\n",
    "    l = line.replace('\"',\"\")\n",
    "    l = l.replace('\\n',\"\")\n",
    "    l = l.split('\\t')\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tp(sentence):\n",
    "    \"\"\" Clean the sentence by removing special char. \"\"\"\n",
    "    s = sentence.replace(\"\\r\\n\\s\\s+\",\" \")\n",
    "    s = s.replace(\"\\r\\n\",\" \")\n",
    "    s = s.replace(\"\\s\\s+\",\" \")\n",
    "    s = s.replace(\"\\\\.\",\" \")\n",
    "    s = s.replace(\"\\\\r\\\\n\",\" \")\n",
    "    p = re.compile(r'<.*?>')\n",
    "    return p.sub('', s)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_occurences(list_sentences, dict_occ, tokenizer1,tokenizer2, list_entities):\n",
    "    \"\"\" Count number of time each entity in list_entities is mentioned in list_sentences. \"\"\"\n",
    "\n",
    "    for s in list_sentences:\n",
    "        #Split line into words with tokenizer to detetc entity\n",
    "        line = s.replace(\",\",\"\")\n",
    "        line_splited = word_tokenize(line)\n",
    "        tokens = tokenizer1.tokenize(line_splited) \n",
    "        tokens = tokenizer2.tokenize(tokens) \n",
    "        tokens = [clean_tp(token) for token in tokens]\n",
    "        for entity in list_entities:\n",
    "            #Increment value of intervention of the entity\n",
    "            if(entity in tokens):\n",
    "\n",
    "                dict_occ[entity] += 1                \n",
    "    rows = [(entity,dict_occ[entity]) for entity in dict_occ]\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_occurences_issue_ENB(list_sentences):\n",
    "    \"\"\" Extract all the occurences for each entities for a specific issue. \"\"\"\n",
    "    #List sentences\n",
    "    sentences = list_tp = list_sentences\n",
    "\n",
    "    # Extract list entities\n",
    "    list_entities = [s.replace('\\n','') for s in list(open('entities_clean.txt'))]\n",
    "    tokens_entities = [l.split(' ') for l in list_entities]\n",
    "\n",
    "    tokenizer1 = MWETokenizer(tokens_entities, separator=' ')\n",
    "    tokenizer2 = MWETokenizer([['G-77','CHINA']], separator='/')\n",
    "\n",
    "    occurences_meetings = []\n",
    "\n",
    "    dict_occurences = dict.fromkeys(list_entities, 0)\n",
    "    occurences_meetings = count_occurences(sentences, dict_occurences, tokenizer1,tokenizer2, list_entities)\n",
    "    return occurences_meetings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('ABU', 0),\n ('', 0),\n ('AFGHANISTAN', 0),\n ('AFRICA GROUP', 0),\n ('AFRICAN GROUP', 0),\n ('AILAC', 0),\n ('ALBA', 0),\n ('ALBANIA', 0),\n ('ALBANIA AND MOLDOVA GROUP', 0),\n ('ALGERIA', 0),\n ('G-77/CHINA', 0),\n ('ANGOLA', 0),\n ('ANTIGUA AND BARBUDA', 0),\n ('ANTINGUA AND BARBUDA', 0),\n ('AOSIS', 0),\n ('APEC', 0),\n ('ARAB EMIRATES', 0),\n ('ARAB STATES', 0),\n ('ARAB GROUP', 0),\n ('ARABIAN COUNTRIES GROUP', 0),\n ('ARGENTINA', 0),\n ('ARMENIA', 0),\n ('AUSTRALIA', 0),\n ('AUSTRIA', 0),\n ('AZERBAIJAN', 0),\n ('BAHAMAS', 0),\n ('BAHRAIN', 0),\n ('BANGLADESH', 0),\n ('BARBADOS', 0),\n ('BARBUDA', 0),\n ('BASIC', 0),\n ('BELARUS', 0),\n ('BELGIUM', 0),\n ('BELGUIM', 0),\n ('BELIZE', 0),\n ('BENIN', 0),\n ('BHUTAN', 0),\n ('BINGOS', 0),\n ('BISSAU', 0),\n ('BOLIVA', 0),\n ('BOLIVIA', 0),\n ('BOSNIA AND HERZEGOVINA', 0),\n ('BOTSWANA', 0),\n ('BRAZIL', 0),\n ('BRUNEI', 0),\n ('BULGARIA', 0),\n ('BURKINA FASO', 0),\n ('BURUNDI', 0),\n ('CACAM', 0),\n ('CAMBODIA', 0),\n ('CAMEROON', 0),\n ('CANADA', 0),\n ('CAR', 0),\n ('CARIBBEAN COMMUNITY', 0),\n ('CARICOM', 0),\n ('CARTAGENA DIALOGUE', 0),\n ('CENTRAL AFRICAN REPUBLIC', 0),\n ('CENTRAL AMERICAN GROUP', 0),\n ('CENTRAL AMERICAN STATES', 0),\n ('CENTRAL GROUP', 0),\n ('CFRN', 0),\n ('CG', 0),\n ('CG-11', 0),\n ('CHAD', 0),\n ('CHILE', 0),\n ('CHINA', 0),\n ('CIS', 0),\n ('CLIMATE ALLIANCE', 0),\n ('CLIMATE GROUP', 0),\n ('COALITION FOR RAINFOREST NATIONS', 0),\n ('COLOMBIA', 0),\n ('COLUMBIA', 0),\n ('COMOROS', 0),\n ('CONGO BASIN COUNTRIES', 0),\n ('COOK ISLAND', 0),\n ('COOK ISLANDS', 0),\n ('COSTA RICA', 0),\n (\"COTE D'IVOIRE\", 0),\n ('CROATIA', 1),\n ('CUBA', 0),\n ('CYPRUS', 0),\n ('CZECH REPUBLIC', 0),\n ('DEMOCRATIC REPUBLIC OF CONGO', 0),\n ('DENMARK', 0),\n ('DJIBOUTI', 0),\n ('DOMINICA', 0),\n ('DOMINICAN REPUBLIC', 0),\n ('DRC', 0),\n ('ECUADOR', 0),\n ('EGYPT', 0),\n ('EIG', 0),\n ('EIT', 0),\n ('EL SALVADOR', 0),\n ('ENVIRONMENTAL INTEGRITY GROUP', 0),\n ('ERITREA', 0),\n ('ESTONIA', 0),\n ('ETHIOPIA', 0),\n ('EU', 0),\n ('EUROPEAN UNION', 0),\n ('FIJI', 0),\n ('FINLAND', 0),\n ('FRANCE', 0),\n ('G77', 0),\n ('G77/CHINA', 0),\n ('G77-CHINA', 0),\n ('G77 & CHINA', 0),\n ('GABON', 0),\n ('GAMBIA', 0),\n ('GEORGIA', 0),\n ('GERMANY', 0),\n ('GHANA', 0),\n ('GREECE', 0),\n ('GRENADA', 0),\n ('GROUP OF NINE', 0),\n ('GRULAC', 0),\n ('GUATEMALA', 0),\n ('GUINEA', 0),\n ('GUINEA BISSAU', 0),\n ('GUYANA', 0),\n ('HAC', 0),\n ('HAITI', 0),\n ('HONDURAS', 0),\n ('HUNGARY', 0),\n ('ICELAND', 0),\n ('INDIA', 0),\n ('INDIGENOUS CAUCUS', 0),\n ('INDONESIA', 0),\n ('IRAN', 0),\n ('IRAQ', 0),\n ('IRELAND', 0),\n ('ISRAEL', 0),\n ('ITALY', 0),\n ('JAMAICA', 0),\n ('JAPAN', 0),\n ('JORDAN', 0),\n ('JUSCANZ', 0),\n ('JUSSCANNZ', 0),\n ('JUSSCANZ', 0),\n ('SYRIA', 0),\n ('CAPE VERDE', 0),\n ('KAZAKHSTAN', 0),\n ('KAZAKSTAN', 0),\n ('KENYA', 0),\n ('KIRIBATI', 0),\n ('KOREA', 0),\n ('KUWAIT', 0),\n ('KYRGYZSTAN', 0),\n ('ST. VINCENT AND THE GRENADINES', 0),\n ('LAOS', 0),\n ('LATIN AMERICA', 0),\n ('LATVIA', 0),\n ('LDC', 0),\n ('LDC GROUP', 0),\n ('LDCS', 0),\n ('LEBANON', 0),\n ('LESOTHO', 0),\n ('LIBERIA', 0),\n ('LIBYA', 0),\n ('LICHTENSTEIN', 0),\n ('LIECHTENSTEIN', 0),\n ('LITHUANIA', 0),\n ('LMDC', 0),\n ('LUXEMBOURG', 0),\n ('MACEDONIA', 0),\n ('MADAGASCAR', 0),\n ('MALAWI', 0),\n ('MALAYSIA', 0),\n ('MALDIVES', 0),\n ('MALI', 0),\n ('MALTA', 0),\n ('MARSHALL ISLANDS', 0),\n ('MAURITANIA', 0),\n ('MAURITIUS', 0),\n ('MEX', 0),\n ('MEXICO', 0),\n ('MICRONESIA', 0),\n ('MOLDOVA', 0),\n ('MONACO', 0),\n ('MONGOLIA', 0),\n ('MOROCCO', 0),\n ('MOZAMBIQUE', 0),\n ('MYANMAR', 0),\n ('NAMIBIA', 0),\n ('NAURU', 0),\n ('SADC', 0),\n ('SOMALIA', 0),\n ('YUGOSLAVIA', 0),\n ('NEPAL', 0),\n ('NETHERLANDS', 0),\n ('NEW GUINEA', 0),\n ('NEW ZEALAND', 0),\n ('NICARAGUA', 0),\n ('NIGER', 0),\n ('NIGERIA', 0),\n ('NIUE', 0),\n ('NORWARY', 0),\n ('NORWAY', 0),\n ('NZ', 0),\n ('OAS', 0),\n ('OECD', 0),\n ('OMAN', 0),\n ('OPEC', 0),\n ('PAKISTAN', 0),\n ('PALAU', 0),\n ('PALESTINE', 0),\n ('PANAMA', 0),\n ('PAPUA NEW GUINEA', 0),\n ('PARAGUAY', 0),\n ('PERU', 0),\n ('PHILIPPINES', 0),\n ('PHILLIPINES', 0),\n ('PHILLIPPINES', 0),\n ('POLAND', 0),\n ('PORTUGAL', 0),\n ('PSIDS', 0),\n ('QATAR', 0),\n ('REPUBLIC OF CONGO', 0),\n ('REPUBLIC OF KOREA', 0),\n ('ROMANIA', 0),\n ('RUSSIA', 0),\n ('RWANDA', 0),\n ('SAINT LUCIA', 0),\n ('SAMOA', 0),\n ('SAUDI', 0),\n ('SAUDI ARABIA', 1),\n ('SAUDIA ARABIA', 0),\n ('SENEGAL', 0),\n ('SERBIA', 0),\n ('SERBIA AND MONTENEGRO', 0),\n ('SEYCHELLES', 0),\n ('SIDS', 0),\n ('SIERRA LEONE', 0),\n ('SINGAPORE', 0),\n ('SLOVAKIA', 0),\n ('SLOVENIA', 0),\n ('SOLOMON ISLANDS', 0),\n ('SOUTH AFRICA', 0),\n ('SOUTH EAST ASIA', 0),\n ('SOUTH SUDAN', 0),\n ('SPAIN', 0),\n ('SRI LANKA', 0),\n ('SUDAN', 0),\n ('SURINAME', 0),\n ('SWAZILAND', 0),\n ('SWEDEN', 0),\n ('SWITERLAND', 0),\n ('SWITZER', 0),\n ('SWITZERLAND', 0),\n ('TAJIKISTAN', 0),\n ('TANZANIA', 0),\n ('THAILAND', 0),\n ('THE BAHAMAS', 0),\n ('THE GAMBIA', 0),\n ('TIMOR LESTE', 0),\n ('TOBAGO', 0),\n ('TOGO', 0),\n ('TONGA', 0),\n ('TRINDAD AND TOBAGO', 0),\n ('TRINIDAD', 0),\n ('TRININDAD AND TOBAGO', 0),\n ('TUNISIA', 0),\n ('TURKEY', 0),\n ('TURKMENISTAN', 0),\n ('TUVALU', 0),\n ('UAE', 0),\n ('UG', 0),\n ('UGANDA', 0),\n ('UK', 0),\n ('UKRAINE', 0),\n ('UMBRELLA GROUP', 0),\n ('URAGUAY', 0),\n ('URUGUAY', 0),\n ('US', 0),\n ('USA', 0),\n ('UZBEKISTAN', 0),\n ('VANUATU', 0),\n ('VENEZUELA', 0),\n ('VENEZULA', 0),\n ('VIET NAM', 0),\n ('VIETNAM', 0),\n ('VISEGRAD', 0),\n ('WEOG', 0),\n ('YEMEN', 0),\n ('ZAIRE', 0),\n ('ZAMBIA', 0),\n ('ZEALAND', 0),\n ('ZIMABABWE', 0),\n ('ZIMBABWE', 0)]"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "extract_occurences_issue_ENB(list(open('sentences305.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
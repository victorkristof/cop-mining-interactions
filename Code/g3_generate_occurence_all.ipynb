{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "importing Jupyter notebook from a2_extract_list_meetings.ipynb\nimporting Jupyter notebook from a1_compute_list_meeting.ipynb\nimporting Jupyter notebook from c1_extract_paragraphe_issue.ipynb\nIssue  34\nimporting Jupyter notebook from c2_extract_sentence_issue.ipynb\nimporting Jupyter notebook from e1_extract_occ_gen.ipynb\nimporting Jupyter notebook from e2_extract_occ_original.ipynb\nimporting Jupyter notebook from g1_generate_dictionary.ipynb\n"
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import numpy as np\n",
    "import sys\n",
    "import csv\n",
    "import numpy.ma as ma\n",
    "import matplotlib.pyplot as plt\n",
    "import a2_extract_list_meetings as a2\n",
    "import c1_extract_paragraphe_issue as c1\n",
    "import c2_extract_sentence_issue as c2\n",
    "import e1_extract_occ_gen as e1\n",
    "import e2_extract_occ_original as e2 \n",
    "import g1_generate_dictionary as g1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(file):\n",
    "    list_file = []\n",
    "    f = open(file)\n",
    "    for x in csv.reader(f):\n",
    "        list_file.append(x)\n",
    "    return list_file[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_occurrence_issue(occurences_meetings, s):\n",
    "        with open(s, \"w\", newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "        #header\n",
    "                writer.writerow(('entity','interventions'))\n",
    "                writer.writerows(occurences_meetings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_gen(dictionary, original_occ, generated_occ):\n",
    "    combined = []\n",
    "\n",
    "    for eo in original_occ:\n",
    "        list_eo = []\n",
    "        for eg in generated_occ:\n",
    "            if(eg[0] in dictionary[eo[0]]):\n",
    "                list_eo.append(eg)\n",
    "        combined.append(list_eo)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stat_egals(generated_occ, original_occ,number):\n",
    "    original = []\n",
    "    generated = []\n",
    "    for i in range(len(original_occ)):\n",
    "        original.append((number,original_occ[i][0],original_occ[i][1]))\n",
    "        g = sorted(generated_occ[i],key=lambda x: x[1], reverse=True)[0]\n",
    "        generated.append((number,g[0],g[1]))\n",
    "    return original,generated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_interventions(number, list_sentences):\n",
    "    \"\"\"Extract the intervention for both dataset and keep only the one that match the dictionary\"\"\"\n",
    "    #Load the occurences for the original and generated file, and the dictionary\n",
    "    original_occ = e2.extract_occurences_issue(number)\n",
    "    gen_occ = e1.extract_occurences_issue_ENB(list_sentences, number)\n",
    "\n",
    "    #dictionary = g1.compute_dictionary()\n",
    "\n",
    "    #Combine element same key\n",
    "    #generated_occ= combine_gen(dictionary, original_occ, gen_occ)\n",
    "    # Original and generated occurence with only the entities into the dictionary\n",
    "    #original,generated = create_stat_egals(generated_occ, original_occ, number)\n",
    "\n",
    "    return original_occ,gen_occ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract__all_intervention():\n",
    "    \"\"\"Extract the intervention for all the issues in the original dataset and write them into .csv file\"\"\"\n",
    "    # Extract all the issue number in the original dataset\n",
    "    list_meetings = open_file('list_meetings.csv')\n",
    "    list_issues = a2.issues_list(list_meetings)\n",
    "\n",
    "    list_generated = []\n",
    "    list_original = []\n",
    "\n",
    "    for i in list_issues:\n",
    "        if(45 < int(i) and int(i) < 594):\n",
    "            list_paragraphes = c1.extract_paragraphes_from_issue(int(i))\n",
    "            list_sentences = c2.sentences(list_paragraphes)\n",
    "            original,generated = extract_interventions(int(i), list_sentences)\n",
    "\n",
    "            list_generated += generated\n",
    "            list_original += original\n",
    "    return list_generated, list_original\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Issue  46\nIssue  47\nIssue  48\nIssue  49\nIssue  50\nIssue  51\nIssue  52\nIssue  53\nIssue  54\nIssue  55\nIssue  56\nIssue  57\nIssue  58\nIssue  59\nIssue  60\nIssue  61\nIssue  62\nIssue  63\nIssue  64\nIssue  65\nIssue  66\nIssue  67\nIssue  68\nIssue  69\nIssue  70\nIssue  71\nIssue  72\nIssue  73\nIssue  74\nIssue  75\nIssue  76\nIssue  77\nIssue  78\nIssue  79\nIssue  80\nIssue  81\nIssue  82\nIssue  83\nIssue  84\nIssue  85\nIssue  86\nIssue  87\nIssue  88\nIssue  89\nIssue  90\nIssue  91\nIssue  92\nIssue  93\nIssue  94\nIssue  95\nIssue  96\nIssue  97\nIssue  98\nIssue  99\nIssue  100\nIssue  101\nIssue  102\nIssue  103\nIssue  104\nIssue  105\nIssue  106\nIssue  107\nIssue  108\nIssue  109\nIssue  110\nIssue  111\nIssue  112\nIssue  113\nIssue  114\nIssue  115\nIssue  116\nIssue  117\nIssue  118\nIssue  119\nIssue  120\nIssue  121\nIssue  122\nIssue  123\nIssue  124\nIssue  125\nIssue  126\nIssue  127\nIssue  128\nIssue  129\nIssue  130\nIssue  131\nIssue  132\nIssue  133\nIssue  134\nIssue  135\nIssue  136\nIssue  137\nIssue  138\nIssue  139\nIssue  140\nIssue  141\nIssue  142\nIssue  143\nIssue  144\nIssue  145\nIssue  146\nIssue  147\nIssue  148\nIssue  149\nIssue  150\nIssue  151\nIssue  152\nIssue  153\nIssue  154\nIssue  155\nIssue  156\nIssue  157\nIssue  158\nIssue  159\nIssue  160\nIssue  161\nIssue  162\nIssue  163\nIssue  164\nIssue  165\nIssue  166\nIssue  167\nIssue  168\nIssue  169\nIssue  170\nIssue  171\nIssue  172\nIssue  173\nIssue  174\nIssue  175\nIssue  176\nIssue  177\nIssue  178\nIssue  179\nIssue  180\nIssue  181\nIssue  182\nIssue  183\nIssue  184\nIssue  185\nIssue  186\nIssue  187\nIssue  188\nIssue  189\nIssue  190\nIssue  191\nIssue  192\nIssue  193\nIssue  194\nIssue  195\nIssue  196\nIssue  197\nIssue  198\nIssue  199\nIssue  200\nIssue  201\nIssue  202\nIssue  203\nIssue  204\nIssue  205\nIssue  206\nIssue  207\nIssue  208\nIssue  209\nIssue  210\nIssue  211\nIssue  212\nIssue  213\nIssue  214\nIssue  215\nIssue  216\nIssue  217\nIssue  218\nIssue  219\nIssue  220\nIssue  221\nIssue  222\nIssue  223\nIssue  224\nIssue  225\nIssue  226\nIssue  227\nIssue  228\nIssue  229\nIssue  230\nIssue  231\nIssue  232\nIssue  233\nIssue  234\nIssue  235\nIssue  236\nIssue  237\nIssue  238\nIssue  239\nIssue  240\nIssue  241\nIssue  242\nIssue  243\nIssue  244\nIssue  245\nIssue  246\nIssue  247\nIssue  248\nIssue  249\nIssue  250\nIssue  251\nIssue  252\nIssue  253\nIssue  254\nIssue  255\nIssue  256\nIssue  257\nIssue  258\nIssue  259\nIssue  260\nIssue  261\nIssue  262\nIssue  263\nIssue  264\nIssue  265\nIssue  266\nIssue  267\nIssue  268\nIssue  269\nIssue  270\nIssue  271\nIssue  272\nIssue  273\nIssue  274\nIssue  275\nIssue  276\nIssue  277\nIssue  278\nIssue  279\nIssue  280\nIssue  281\nIssue  282\nIssue  283\nIssue  284\nIssue  285\nIssue  286\nIssue  287\nIssue  288\nIssue  289\nIssue  290\nIssue  291\nIssue  292\nIssue  293\nIssue  294\nIssue  295\nIssue  296\nIssue  297\nIssue  298\nIssue  299\nIssue  300\nIssue  301\nIssue  302\nIssue  303\nIssue  304\nIssue  305\nIssue  306\nIssue  307\nIssue  308\nIssue  309\nIssue  310\nIssue  311\nIssue  312\nIssue  313\nIssue  314\nIssue  315\nIssue  316\nIssue  317\nIssue  318\nIssue  319\nIssue  320\nIssue  321\nIssue  322\nIssue  323\nIssue  324\nIssue  325\nIssue  326\nIssue  327\nIssue  328\nIssue  329\nIssue  330\nIssue  331\nIssue  332\nIssue  333\nIssue  334\nIssue  335\nIssue  336\nIssue  337\nIssue  338\nIssue  339\nIssue  340\nIssue  341\nIssue  342\nIssue  343\nIssue  344\nIssue  345\nIssue  346\nIssue  347\nIssue  348\nIssue  349\nIssue  350\nIssue  351\nIssue  352\nIssue  353\nIssue  354\nIssue  355\nIssue  356\nIssue  357\nIssue  358\nIssue  359\nIssue  360\nIssue  361\nIssue  362\nIssue  363\nIssue  364\nIssue  365\nIssue  366\nIssue  367\nIssue  368\nIssue  369\nIssue  370\nIssue  371\nIssue  372\nIssue  373\nIssue  374\nIssue  375\nIssue  376\nIssue  377\nIssue  378\nIssue  379\nIssue  380\nIssue  381\nIssue  382\nIssue  383\nIssue  384\nIssue  385\nIssue  386\nIssue  387\nIssue  388\nIssue  389\nIssue  390\nIssue  391\nIssue  392\nIssue  393\nIssue  394\nIssue  395\nIssue  396\nIssue  397\nIssue  398\nIssue  399\nIssue  400\nIssue  401\nIssue  402\nIssue  403\nIssue  404\nIssue  405\nIssue  406\nIssue  407\nIssue  408\nIssue  409\nIssue  410\nIssue  411\nIssue  412\nIssue  413\nIssue  414\nIssue  415\nIssue  416\nIssue  417\nIssue  418\nIssue  419\nIssue  420\nIssue  421\nIssue  422\nIssue  423\nIssue  424\nIssue  425\nIssue  426\nIssue  427\nIssue  428\nIssue  429\nIssue  430\nIssue  431\nIssue  432\nIssue  433\nIssue  434\nIssue  435\nIssue  436\nIssue  437\nIssue  438\nIssue  439\nIssue  440\nIssue  441\nIssue  442\nIssue  443\nIssue  444\nIssue  445\nIssue  446\nIssue  447\nIssue  448\nIssue  449\nIssue  450\nIssue  451\nIssue  452\nIssue  453\nIssue  454\nIssue  455\nIssue  456\nIssue  457\nIssue  458\nIssue  459\nIssue  460\nIssue  461\nIssue  462\nIssue  463\nIssue  464\nIssue  465\nIssue  466\nIssue  467\nIssue  468\nIssue  469\nIssue  470\nIssue  471\nIssue  472\nIssue  473\nIssue  474\nIssue  475\nIssue  476\nIssue  477\nIssue  478\nIssue  479\nIssue  480\nIssue  481\nIssue  482\nIssue  483\nIssue  484\nIssue  485\nIssue  486\nIssue  487\nIssue  488\nIssue  489\nIssue  490\nIssue  491\nIssue  492\nIssue  493\nIssue  494\nIssue  495\nIssue  496\nIssue  497\nIssue  498\nIssue  499\nIssue  500\nIssue  501\nIssue  502\nIssue  503\nIssue  504\nIssue  505\nIssue  506\nIssue  507\nIssue  508\nIssue  509\nIssue  510\nIssue  511\nIssue  512\nIssue  513\nIssue  514\nIssue  515\nIssue  516\nIssue  517\nIssue  518\nIssue  519\nIssue  520\nIssue  521\nIssue  522\nIssue  523\nIssue  524\nIssue  525\nIssue  526\nIssue  527\nIssue  528\nIssue  529\nIssue  530\nIssue  531\nIssue  532\nIssue  533\nIssue  534\nIssue  535\nIssue  536\nIssue  537\nIssue  538\nIssue  539\nIssue  540\nIssue  541\nIssue  542\nIssue  543\nIssue  544\nIssue  545\nIssue  546\nIssue  547\nIssue  548\nIssue  549\nIssue  550\nIssue  551\nIssue  552\nIssue  553\nIssue  554\nIssue  555\nIssue  556\nIssue  557\nIssue  558\nIssue  559\nIssue  560\nIssue  561\nIssue  562\nIssue  563\nIssue  564\nIssue  565\nIssue  566\nIssue  567\nIssue  568\nIssue  569\nIssue  570\nIssue  571\nIssue  572\nIssue  573\nIssue  574\nIssue  575\nIssue  576\nIssue  577\nIssue  578\nIssue  579\nIssue  580\nIssue  581\nIssue  582\nIssue  583\nIssue  584\nIssue  585\nIssue  586\nIssue  587\nIssue  588\nIssue  589\nIssue  590\nIssue  591\nIssue  592\nIssue  593\n"
    }
   ],
   "source": [
    "list_generated, list_original = extract__all_intervention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_o = np.sum([int(x[1]) for x in list_original])\n",
    "num_g = np.sum([int(x[2]) for x in list_generated])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "24154"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "num_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "29853"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "num_g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "source": [
    "d = define_dict_ref()\n",
    "\n",
    "swiss, us, china, saudi_arabia= extract_occurence_by_list_ref(d)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "index = np.arange(len(us))\n",
    "df = pd.DataFrame({'Switzerland': swiss,'China': china, 'US': us, 'Saudi Arabia': saudi_arabia}, index=index)\n",
    "\n",
    "ax = df.plot(figsize=(25,9),kind='bar',title='Number of intervention for each meetings between 1995-2013')\n",
    "ax.set_xlabel(\"Meetings in chronological order\")\n",
    "ax.set_ylabel(\"Number of interventions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bit15afa4b5d9a84aa2af9f4a46f3f973aa",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
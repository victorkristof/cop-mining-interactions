{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bit162d60da764a43dc83edcb73a443ab01",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "importing Jupyter notebook from g1_generate_dictionary.ipynb\nimporting Jupyter notebook from e2_extract_occ_original.ipynb\nimporting Jupyter notebook from e1_extract_occ_gen.ipynb\n"
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import g1_generate_dictionary as dict_gen\n",
    "import e2_extract_occ_original as stat_original\n",
    "import e1_extract_occ_gen as stat_gen\n",
    "import numpy as np\n",
    "import sys\n",
    "import csv\n",
    "import numpy.ma as ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_stat_orig(dictionary,orig_occ):\n",
    "     \"\"\"Take the occurences for only the entities in the dicitonary for the original dataset\"\"\"\n",
    "    stat_original = []\n",
    "    for o in orig_occ:\n",
    "        if(len(dictionary[o[0]]) !=0 ):\n",
    "            stat_original.append((o[0],o[1]))\n",
    "    return stat_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_stat_gen(dictionary, gen_occ):\n",
    "    \"\"\"Take the occurences for only the entities in the dicitonary for the generated dataset\"\"\"\n",
    "    stat_g = []\n",
    "    for o in gen_occ:\n",
    "        if(o[0] in sum(dictionary.values(),[])):\n",
    "            stat_g.append((o[0],o[1]))\n",
    "    return stat_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_gen(dictionary, original_occ, generated_occ):\n",
    "    \"\"\"Combine the entities that have different spellings in generated_occ with the dictionary\"\"\"\n",
    "    combined = []\n",
    "    for eo in original_occ:\n",
    "        list_eo = []\n",
    "        for eg in generated_occ:\n",
    "            if(eg[0] in dictionary[eo[0]]):\n",
    "                list_eo.append(eg)\n",
    "        combined.append(list_eo)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_ori_gen(generated_occ, original_occ):\n",
    "    \"\"\"From all the entities in generated_occ keep only the one with the max number of interventions. Return both generated and original occurences with the same order inside (index i : both the same entity's interventions)\"\"\"\n",
    "    original = []\n",
    "    generated = []\n",
    "    for i in range(len(original_occ)):\n",
    "        original.append(original_occ[i][1])\n",
    "        generated.append(sorted(generated_occ[i],key=lambda x: x[1], reverse=True)[0][1])\n",
    "\n",
    "    return original,generated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_interventions(number, list_sentences):\n",
    "    \"\"\"Extract the intervention for both dataset and keep only the one that match the dictionary for one issue\"\"\"\n",
    "    #Load the occurences for the original and generated file, and the dictionary\n",
    "    original_occ = stat_original.extract_occurences_issue(number)\n",
    "    gen_occ = stat_gen.extract_occurences_issue_ENB(list_sentences)\n",
    "    dictionary = dict_gen.compute_dictionary()\n",
    "    \n",
    "    #Take only entities in the dictionary (to have same length)\n",
    "    original_occ = extract_stat_orig(dictionary,original_occ)\n",
    "    generated_occ = extract_stat_gen(dictionary, gen_occ)\n",
    "\n",
    "    #Combine element same key\n",
    "    generated_occ= combine_gen(dictionary, original_occ, generated_occ)\n",
    "\n",
    "    # x: intervention of the original file\n",
    "    # y: intervention of the generated file \n",
    "    x,y = compare_ori_gen(generated_occ, original_occ)\n",
    "\n",
    "    return x,y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correlation_coefficient(number, list_sentences):\n",
    "    \"\"\"Compute the coeeficient of correlation of intervention between the dataset for one speicific issue\"\"\"\n",
    "    x,y = extract_interventions(number, list_sentences)\n",
    "    x =  np.array(x).astype(np.float)\n",
    "    y = np.array(y).astype(np.float)\n",
    "\n",
    "    return np.corrcoef(x,y)"
   ]
  }
 ]
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# g1_generated_dictionary\n",
    "Create a dictionary to be able to match the entities in the original dataset and the entities generated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import csv\n",
    "import Levenshtein\n",
    "from difflib import SequenceMatcher\n",
    "import country_converter as coco\n",
    "import numpy as np\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.disable(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_statement_count():\n",
    "    \"\"\"Extract from the original dataset all the interventions.\"\"\"\n",
    "    f = open('Text/statements_count.csv')\n",
    "    dataset = csv.reader(f)\n",
    "    lines = []\n",
    "    for d in dataset:\n",
    "        if(len(d) != 0):\n",
    "            line = d[0].split('\\t')\n",
    "            lines.append((line[0],line[2],line[1]))\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities():\n",
    "    \"\"\"Extract from the original dataset all parties or party grouping.\"\"\"\n",
    "    dataset = extract_statement_count()\n",
    "    entities = set()\n",
    "    for d in dataset:\n",
    "        entities.add(d[0])\n",
    "\n",
    "    return list(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_original = extract_entities()\n",
    "entities_generated = [p.replace('\\n','') for p in list(open(\"Text/entities_clean.txt\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract_[] are all function to map the entities in the original data to the one generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_initial(entities_gen, dict_e):\n",
    "    \"\"\"Function that find match with initials. \"\"\"\n",
    "    entities_original = extract_entities()\n",
    "    for eg in entities_gen:\n",
    "        for e in entities_original:\n",
    "            d = Levenshtein.ratio(eg,e.upper())\n",
    "            if(d > 0.9):\n",
    "                dict_e[e].append(eg)\n",
    "    \n",
    "    return dict_e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_title(entities_gen, dict_e):\n",
    "    \"\"\"Function that find match with title case. \"\"\"\n",
    "    entities_original = extract_entities()\n",
    "    for eg in entities_gen:\n",
    "        for e in entities_original:\n",
    "            d = Levenshtein.ratio(eg.title(),e.title())\n",
    "            if(d > 0.9):\n",
    "                dict_e[e].append(eg)\n",
    "\n",
    "    return dict_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_normal(entities_gen, dict_e):\n",
    "    \"\"\"Function that find match with lower case. \"\"\"\n",
    "    entities_original = extract_entities()\n",
    "    for eg in entities_gen:\n",
    "        for e in entities_original:\n",
    "            d1 = Levenshtein.ratio(eg.lower(),e.lower())\n",
    "            if(d1 > 0.9):\n",
    "                dict_e[e].append(eg)\n",
    "    return dict_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_g77china(entities_gen, dict_e):\n",
    "    \"\"\"Function that find match all different spellings of the G77. \"\"\"\n",
    "    entities_original = extract_entities()\n",
    "    entities = []\n",
    "    for eg in entities_gen:\n",
    "        s = 'G77'\n",
    "        if(eg == 'G-77/CHINA' or eg =='G-77 AND CHINA'):\n",
    "            dict_e[s].append(eg)\n",
    "        if(eg == 'G-77/ CHINA'):\n",
    "            dict_e[s].append(eg)\n",
    "        if(eg == 'said the G-77/China'):\n",
    "            dict_e[s].append(eg)\n",
    "        if(eg == 'for the G-77/China' or eg == 'for the G-77/ China' or eg == 'for the Group of 77 and China'):\n",
    "            dict_e[s].append(eg)\n",
    "        egs = eg[:3]\n",
    "        d1 = Levenshtein.ratio(s,egs)\n",
    "        if(d1 > 0.95):\n",
    "            dict_e[s].append(eg)\n",
    "\n",
    "    return dict_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ldc(entities_gen, dict_e):\n",
    "    \"\"\"Function that find match all different spellings of the LDCs. \"\"\"\n",
    "    entities_original = extract_entities()\n",
    "    entities = []\n",
    "    for eg in entities_gen:\n",
    "        s = 'LEAST DEVELOPED COUNTRIES'\n",
    "        if(eg == 'for the LDCs' or eg == 'for the Least Developed Countries' or eg == 'for LDCs' or eg == 'LDC GROUP'):\n",
    "            dict_e['LDCs'].append(eg)\n",
    "        d1 = Levenshtein.ratio(s,eg)\n",
    "        if(d1 > 0.95):\n",
    "            dict_e['LDCs'].append(eg)\n",
    "\n",
    "    return dict_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_aosis(entities_gen, dict_e):\n",
    "    \"\"\"Function that find match all different spellings of the AOSIS. \"\"\"\n",
    "    entities_original = extract_entities()\n",
    "    entities = []\n",
    "    for eg in entities_gen:\n",
    "        if(eg == 'ALLIANCE OF SMALL ISLAND STATES'):\n",
    "            dict_e['AOSIS'].append(eg)\n",
    "    return dict_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sadc(entities_gen, dict_e):\n",
    "    \"\"\"Function that find match all different spellings of the SADS. \"\"\"\n",
    "    entities_original = extract_entities()\n",
    "    entities = []\n",
    "    for eg in entities_gen:\n",
    "        s = 'SADC'\n",
    "        d1 = Levenshtein.ratio(s,eg)\n",
    "        if(d1 > 0.95):\n",
    "            dict_e['Southern Africa Development Community'].append(eg)\n",
    "\n",
    "    return dict_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_eig(entities_gen, dict_e):\n",
    "    \"\"\"Function that find match all different spellings of the EIG. \"\"\"\n",
    "    entities_original = extract_entities()\n",
    "    entities = []\n",
    "    for eg in entities_gen:\n",
    "        if(eg == 'for the Environmental Integrity Group'):\n",
    "            dict_e['Environmental Integrity Group'].append(eg)\n",
    "        s = 'EIG'\n",
    "        d1 = Levenshtein.ratio(s,eg)\n",
    "        if(d1 > 0.95):\n",
    "            dict_e['Environmental Integrity Group'].append(eg)\n",
    "\n",
    "    return dict_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remaining_original(dict_entities):\n",
    "    \"\"\"Find all the entities that still not have a match.\"\"\"\n",
    "    list_remain_original = []\n",
    "    for e in dict_entities:\n",
    "        if(len(dict_entities[e]) == 0 or e == 'Russian Federation'):\n",
    "           list_remain_original.append(e)\n",
    "           \n",
    "    return list_remain_original\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(entities_original):\n",
    "    \"\"\"Create a dictionary for all the entities into the original dataset.\"\"\"\n",
    "    dict_e = {}\n",
    "    for e in entities_original:\n",
    "        dict_e[e] = []\n",
    "    dict_e['Southern African Development Community'] = []\n",
    "    return dict_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching(entities_generated, remain_original, dict_entities):\n",
    "    \"\"\"Use the library contry-convertor to match the remaining entities of the originla dataset\"\"\"\n",
    "    master_list = entities_generated\n",
    "    match_these = remain_original\n",
    "    matching_dict = coco.match(match_these, master_list)\n",
    "    for e in matching_dict:\n",
    "        if(matching_dict[e] !='not_found'):\n",
    "\n",
    "            if(type(matching_dict[e]) ==list):\n",
    "                dict_entities[e] += matching_dict[e]\n",
    "            else:\n",
    "                dict_entities[e].append(matching_dict[e])\n",
    "                \n",
    "    return dict_entities\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_initials(entities_generated, dict_entities):\n",
    "    \"\"\"Function that find match the inital by creating them. \"\"\"\n",
    "    list_remain_original = []\n",
    "    u = ''\n",
    "    for e in dict_entities:\n",
    "        initials = u.join([x[0].upper() for x in e.split(' ')])\n",
    "        for eg in entities_generated:\n",
    "            d1 = Levenshtein.ratio(initials,eg)\n",
    "            if(d1 > 0.90):\n",
    "                dict_entities[e].append(eg)\n",
    "\n",
    "    return dict_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_groups(entities_generated, dict_entities):\n",
    "    \"\"\"Function that find match groups. \"\"\"\n",
    "    list_remain_original = []\n",
    "    u = ''\n",
    "    for e in dict_entities:\n",
    "        initials = u.join([x[0].upper() for x in e.split(' ')])\n",
    "        for eg in entities_generated:\n",
    "            eg_g = eg.replace('GROUP','')\n",
    "            d1 = Levenshtein.ratio(initials,eg_g)\n",
    "            if(d1 > 0.95):\n",
    "                dict_entities[e].append(eg)\n",
    "\n",
    "    return dict_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_last_chance(dict_entities):\n",
    "    \"\"\"Try to match the entities remaining with words with ratio > 0.8\"\"\"\n",
    "    entities_generated = [p.replace('\\n','') for p in list(open(\"Text/entities_clean.txt\"))]\n",
    "    remain_original = []\n",
    "    for e in dict_entities:\n",
    "        if(len(dict_entities[e]) == 0):\n",
    "            remain_original.append(e)\n",
    "\n",
    "    for er in remain_original:\n",
    "        for e in entities_generated:\n",
    "            d = Levenshtein.ratio(er.upper(),e)\n",
    "            if(d > 0.8):\n",
    "\n",
    "                dict_entities[er].append(e)\n",
    "\n",
    "    return dict_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_special_cases(dict_entities):\n",
    "    \"\"\"Special cases added by hand. \"\"\"\n",
    "    dict_entities['EU'].append('EUROPEAN UNION')\n",
    "    dict_entities['Syrian Arab Republic'].append('SYRIA')\n",
    "    dict_entities['United States'].append('US')\n",
    "    dict_entities['United Arab Emirates'].append('ARAB EMIRATES')\n",
    "    dict_entities['Umbrella Group'].append('for the Umbrella Group')\n",
    "    dict_entities['EU'].append('for the European Union')\n",
    "    dict_entities['Arab Group'].append('for the Arab Group')\n",
    "    dict_entities['African Group'].append('for the Africa Group')\n",
    "    dict_entities['Arab Group'].append('for the League of Arab States')\n",
    "    dict_entities['Like Minded Developing Countries'].append('for the Like Minded Developing Countries')\n",
    "    dict_entities['Group of 9'].append('GROUP OF NINE')\n",
    "    dict_entities['Switzerland'].append('SWITZER')\n",
    "    dict_entities['Like Minded Developing Countries'].append('LMDC')\n",
    "    dict_entities['Like Minded Developing Countries'].append('LMDCS')\n",
    "    dict_entities['Central Group Eleven'].append('CG-11')\n",
    "    dict_entities['Micronesia'].append('FEDERATED STATES OF MICRONESIA')\n",
    "    dict_entities['Arab Group'].append('ARAB STATES')\n",
    "    dict_entities['Congo, Republic'].append('THE DEMOCRATIC REPUBLIC OF THE CONGO')\n",
    "    dict_entities['Belgium'].append('BELGUIM')\n",
    "    dict_entities['St. Vincent and the Grenadines'].append('SAINT VINCENT AND THE GRENADINES')\n",
    "    dict_entities['Uruguay'].append('URAGUAY')\n",
    "    dict_entities['Central America'].append('CENTRAL AMERICAN STATES')\n",
    "    dict_entities['Central America'].append('CENTRAL AMERICAN GROUP')\n",
    "    dict_entities['Southern African Development Community'].append('SADC')\n",
    "    return dict_entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dictionary():\n",
    "    \"\"\"Generated the dictionary between the original entities and the one generated\"\"\"\n",
    "    dict_entities = create_dict(entities_original)\n",
    "    dict_entities = extract_initial(entities_generated, dict_entities)\n",
    "    dict_entities = extract_title(entities_generated, dict_entities)\n",
    "    dict_entities = extract_normal(entities_generated, dict_entities)\n",
    "    dict_entities = extract_g77china(entities_generated, dict_entities)\n",
    "    dict_entities = extract_sadc(entities_generated, dict_entities)\n",
    "    dict_entities = extract_aosis(entities_generated, dict_entities)\n",
    "    dict_entities = extract_eig(entities_generated, dict_entities)\n",
    "    dict_entities = extract_ldc(entities_generated, dict_entities)\n",
    "    dict_entities = create_initials(entities_generated, dict_entities)\n",
    "    dict_entities = find_groups(entities_generated, dict_entities)\n",
    "    remaining_orig = remaining_original(dict_entities)\n",
    "    dict_entities = matching(entities_generated, remaining_orig , dict_entities)\n",
    "    dict_entities = add_special_cases(dict_entities)\n",
    "\n",
    "    dictionary = compute_last_chance(dict_entities)\n",
    "\n",
    "\n",
    "    for d in dictionary:\n",
    "        dictionary[d] = list(set(dictionary[d]))\n",
    "\n",
    "    return dictionary"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bit15afa4b5d9a84aa2af9f4a46f3f973aa",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
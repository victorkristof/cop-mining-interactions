{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "importing Jupyter notebook from a2_extract_list_meetings.ipynb\nimporting Jupyter notebook from a1_compute_list_meeting.ipynb\nimporting Jupyter notebook from c1_extract_paragraphe_issue.ipynb\nIssue  34\nimporting Jupyter notebook from c2_extract_sentence_issue.ipynb\nimporting Jupyter notebook from e1_extract_occ_gen.ipynb\nimporting Jupyter notebook from e2_extract_occ_original.ipynb\nimporting Jupyter notebook from g1_generate_dictionary.ipynb\n"
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import numpy as np\n",
    "import sys\n",
    "import csv\n",
    "import numpy.ma as ma\n",
    "import matplotlib.pyplot as plt\n",
    "import a2_extract_list_meetings as a2\n",
    "import c1_extract_paragraphe_issue as c1\n",
    "import c2_extract_sentence_issue as c2\n",
    "import e1_extract_occ_gen as e1\n",
    "import e2_extract_occ_original as e2 \n",
    "import g1_generate_dictionary as g1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(file):\n",
    "    \"\"\"Open file that contains all meetings with their information extrated. \"\"\"\n",
    "    list_file = []\n",
    "    f = open(file)\n",
    "    for x in csv.reader(f):\n",
    "        list_file.append(x)\n",
    "    return list_file[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_gen(dictionary, original_occ, generated_occ):\n",
    "    \"\"\"For each entities in original dataset, find map entities generated related to it and take interventions of each.\"\"\"\n",
    "    combined = []\n",
    "    for eo in original_occ:\n",
    "        list_eo = []\n",
    "        for eg in generated_occ:\n",
    "            if(eg[1] in dictionary[eo[0]]):\n",
    "                list_eo.append(eg)\n",
    "        combined.append(list_eo)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stat_egals(generated_occ, original_occ,number):\n",
    "    \"\"\"Keep only interventions of one entity in generated that correspond to one in the original dataset. Take the one with the biggest number of interventions. \"\"\"\n",
    "    original = []\n",
    "    generated = []\n",
    "    for i in range(len(original_occ)):\n",
    "        original.append((number,original_occ[i][0],original_occ[i][1]))\n",
    "        g = sorted(generated_occ[i],key=lambda x: x[2], reverse=True)[0]\n",
    "\n",
    "        generated.append(g)\n",
    "    return original,generated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_interventions(number, list_sentences):\n",
    "    \"\"\"Extract the intervention for both dataset and keep only the one that match the dictionary\"\"\"\n",
    "    #Load the occurences for the original and generated file, and the dictionary\n",
    "    original_occ = e2.extract_occurences_issue(number)\n",
    "\n",
    "    original_occ = [x for x in original_occ if x[0] != 'Korea, Democratic Rep.']\n",
    "\n",
    "    gen_occ = e1.extract_occurences_issue_ENB(list_sentences, number)\n",
    "\n",
    "    dictionary = g1.compute_dictionary()\n",
    "\n",
    "    #Combine element same key\n",
    "    generated_occ= combine_gen(dictionary, original_occ, gen_occ)\n",
    "\n",
    "    # Original and generated occurence with only the entities into the dictionary\n",
    "    original, generated = create_stat_egals(generated_occ, original_occ, number)\n",
    "\n",
    "    return original, generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_intervention():\n",
    "    \"\"\"Extract the intervention for all the issues in the original dataset and write them into .csv file\"\"\"\n",
    "    # Extract all the issue number in the original dataset\n",
    "    list_meetings = open_file('Text/list_meetings.csv')\n",
    "    list_issues = a2.issues_list(list_meetings)\n",
    "\n",
    "    list_generated = []\n",
    "    list_original = []\n",
    "\n",
    "    for i in list_issues:\n",
    "        if(45< int(i) and int(i) < 594):\n",
    "            list_paragraphes = c1.extract_paragraphes_from_issue(int(i))\n",
    "            list_sentences = c2.sentences(list_paragraphes)\n",
    "            original,generated = extract_interventions(int(i), list_sentences)\n",
    "\n",
    "            list_generated += generated\n",
    "            \n",
    "            list_original += original\n",
    "    return list_generated, list_original\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bit15afa4b5d9a84aa2af9f4a46f3f973aa",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}